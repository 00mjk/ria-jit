\subsection{Translating the partitioned code}
The most basic idea for translating the now partitioned basic blocks is to have a fixed association that maps every instruction in the guest ISA to a sequence of instructions native to the host.

The quality of the code that can be generated here strongly depends on the properties of the host and guest architectures in question.
Difficulties can arise due to differences in the instruction operand formats and the type of instruction set architecture the DBT is dealing with.

In our case, as outlined in section~\ref{sec:isa-cmp}, challenges stem from the fact that we are translating code from a load-store architecture using a three-operand instruction format into a register-memory architecture in which (generally) one of the source operands is also the implicit destination operand.
This, for example, means that a single arithmetic \texttt{add rd, rs1, rs2} in RISC-V assembly language generally can not be translated via a single instruction, but rather requires two instructions: moving \texttt{rs1} to \texttt{rd}, then adding the value of \texttt{rs2} to \texttt{rd}.

Opportunities for optimisation lie wherever there is a way to shorten the translation's amount of CPU clock cycles, possibly by employing semantically equivalent native instructions that run in a shorter timespan.
The RISC-V pseudo-instructions (as mentioned in section~\ref{sec:isa-cmp}) are also of some help here~\cite[S. 139]{riscvspec}, along with discoverable patterns in the input assembly.
It is clear, for example, that an instruction like \texttt{xori x10, x10, -1} can be directly translated as a \texttt{not x10}, without needing to resort to \texttt{mov} and \texttt{xor}.
The same principle applies to combinations of multiple instructions.
An \texttt{lui rd, imm1} followed by \texttt{addi rd, rd, imm2} may for example be translated as directly loading the result of the computation \texttt{imm1 + imm2} into \texttt{rd}.

\subsection{Code cache and block handling}
Naturally, the DBT aims to store the translated code in a semi-permanent way, for it is the goal to not have to translate a required section more than once.

For that, we allocate a region of memory reserved for the basic block translations, also called a \textit{code cache}.
Additionally, an index to this memory section is required, since there needs to be a way to quickly reference the blocks residing in the cache and associate them with both the host and guest instruction pointers that identify them during execution.

% todo TLB @noah
% todo info about chaining and optimisations

It is possible that this code cache might fill up during the execution of a large guest program.
If it does, there are two different strategies to handle this issue:
One can either invalidate and purge some or all of the blocks currently residing in the cache, or dynamically resize the cache according to the needs of the guest program~\cite[S. 3]{bintrans}.

Purging the entire cache would require the translator to restart translation on older blocks that might be needed again, introducing a performance overhead that needs to be weighed against the higher memory usage of enlarging the cache.

On the other hand, selective deletion of some of the blocks in the cache is very difficult due to optimisations taken in the context of chaining.
As any chained jumps located in another cached block are dependent on the target block residing in the cache, the target's removal would invalidate these jumps.
It would thus only be possible to either remove all blocks with jump references to the candidate up for removal, or to leave all blocks with jump references in the cache altogether.

\subsection{Register handling and context switching}
\label{sec:context-switch-reg-handle}

\subsubsection{Handling of guest registers}
\label{sec:reg-handle}
As outlined in section~\ref{sec:isa-cmp}, the RISC-V and x86-64 architectures have differing amounts of general purpose registers.
In some way, the state of the 32 general purpose registers \texttt{x1}\footnote{\texttt{x0} is hardwired to a constant zero. All reads will return 0, all writes will be ignored. Hence, this register needs special handling in the DBT, as there is no equivalent construct on x86-64.} to \texttt{x31} and the \texttt{pc} needs to be stored and available to the translations of the identified basic blocks.

As x86-64 only provides for 16 general-purpose registers (\texttt{rax--rdx, rsi, rdi, rsp, rbp and r8--r15}), it is impossible to directly and statically map all guest registers to native host registers.
Adding to the above, due to the fact that some x86-64 registers have special or implicit purposes in some instructions like \texttt{(i)mul} or \texttt{(i)/div}, care must be taken in choosing the registers that can be used for such a mapping.
Keeping a guest register file exclusively in memory, and loading them into native registers when needed within the translations of single instructions is technically possible, especially in light of x86-64's ability to extensively use memory operands in the instructions.
However, this necessitates a large number of memory accesses for both memory operands in the instructions as well as local register allocation within the translated blocks.
Due to the very large performance gain connected to using register operands instead of memory operands, this is also not feasible at scale~\cite[S. 8f.]{bintrans}.

Accordingly, the solution for this problem would be an approach that employs parts of both of these extremes~\cite[S. 9]{bintrans}.
We utilise the tools we designed to discover the most-used registers in the guest programs, and statically map these to general purpose x86-64 registers.
The remaining operands are then dynamically allocated into reserved host registers inside a single block's translation.
The loaded values are then lazily kept in the temporary registers for as long as possible in order to avoid unnecessary memory accesses.
In case the translator requires a value not currently present in a replacement register, the oldest value is written back to the register file in memory and the now free space is utilised for the requested value.
The final write-backs then need to be performed on the block boundaries.

The most-used registers are relatively invariant in between RISC--V executables and their basic blocks, however it might be the case that a single block in such an executable requires a few unique registers fairly often.
By dynamically allocating these into temporaries and statically mapping the most-used registers in general, we save much overhead otherwise spent on memory access to the register file, but do not unnecessarily occupy native register space with seldom accessed guest registers.

\subsubsection{Context switching during execution}
When the code translated by the DBT is executed, it will behave as if it were an independent x86--64 executable.
With the static register mapping in place, these values will thus need to be loaded before any of the translated blocks are called, and stored back before the execution is returned to the DBT\@.

This is called a \textit{context switch}, as we are switching from the host's program state made up of the current register values to that of the guest.
Evidently, preserving both the host and guest's state during execution is critical for the correct program behaviour.

\subsection{System call handling}
\label{sec:syscall-handling}
System calls are also a very important part of enabling the guest program's execution.
Thus, every ISA must offer some way to switch the execution context in the kernel mode for the system call to be handled.

For RISC-V, the instruction \texttt{ECALL} (for \textit{environment call}, formerly \texttt{SCALL}) handles these requests, with the system call number residing in register \texttt{a7} and the arguments being passed in \texttt{a0--a6}.

However, the DBT generally cannot just reorganise the guest argument values and system call identifier according the host's calling convention and relay the system call directly.
The RISC-V guest program expects a different operating system kernel than is present natively on the host;
with that, the system call interface also differs~\cite[S. 2f.]{bintrans}.

In order to handle the \texttt{ECALL} instruction correctly, the translator must thus build the translated instruction to call a specific handler routine not too dissimilar from one that may be found in a kernel.
There, system calls that exist natively on the host architecture as well (like \texttt{write} or \texttt{clock\_gettime}) can usually be passed along to the host's kernel directly.

Care must be taken for system calls that would enable the guest to change the state or context of the host -- an \texttt{mmap} into the translator's memory region, for example, or a call to \texttt{exit} -- these calls must be emulated accordingly to prevent these faults.
In cases where the data structure layout used by the kernels differs, the DBT must also perform necessary actions to adapt the formats to each other.
Some system calls may not exist at all on the native architecture of the host, it is up to the DBT to emulate the required functionality~\cite[S. 2f.]{bintrans}.

\subsection{Floating point extension}
\label{subsec:fp_extension}
Floating point support is a vital part of modern processors, enabling fast computation of real world problems like physics simulations.
While a standard C compiler like the~\textit{gcc}~\cite{gcc-web} is able to emulate floating point arithmetic using integer arithmetic, using the native support of the x86-64 SSE extension is evidently a lot faster.

The main difficulties (and their resolutions) that arise by using the x86-64 SSE extension to translate the RISC-V F- and D-extensions are listed below:
\begin{itemize}
    \item \textbf{Register handling} is similar to the integer register management laid out in section~\ref{sec:context-switch-reg-handle}.
            As mentioned before, the RISC-V architecture consists of 32 floating point registers (\texttt{f0} -- \texttt{f31}) which can hold a single precision (F-extension) or double precision (D-extension) floating point value, whereas the SSE-extension only provides 16 registers \texttt{XMM0} -- \texttt{XMM15}.
            We utilise the tools we designed to discover the most-used registers in the guest programs, and statically map these to x86-64 SSE registers \texttt{XMM2-XMM15}.
            One could use the same dynamic mapping approach for the remaining registers as is being used for general purpose registers, but for simplicity register \texttt{XMM0, XMM1} are just reserved as replacements and missing registers are moved into them from memory temporally.
    \item \textbf{Missing equivalent SSE instruction} can lead to a huge instruction overhead, as emulation often use bit manipulation operations instead.
            Therefore constants or masks need to be moved in from either memory or the general purpose registers because the SSE extension does not support immediates.
            %todo here the reason from down below applies for the fused multiply instructions and VEX encoding (AVX extension)
            The instructions that need to be emulated are unsigned conversion instructions e.g.~\texttt{FCVT.WU.S}, sign-injection instructions e.g.~\texttt{FSGNJ.S}, compare instructions e.g.~\texttt{FEQ.S}, fused multiply-add instructions e.g.~\texttt{FMADD.S} and the \texttt{FCLASS.S} instruction that classifies a floating point value.
            These instructions are not supported by the SSE extension natively.
            As an implementation reference for these instructions, the assembly generated by gcc using the \textit{Godbolt Compiler Explorer}~\cite{godbolt} was used.
    \item \textbf{Rounding modes} are handled differently in the RISC-V architecture, as the rounding mode can be set individually for every instruction.
            The rounding mode of the SSE extension however is controlled by the state of the \texttt{MXCSR} control and status register.
            %todo not the real reason, only the newest intel processors support these instructions, so probably not even the sksmall would support these.
            One could use EVEX-encoding~\cite[S. 374]{intel2017man} to set the rounding mode on a per instruction level for x86-64 as well, but faenc~\cite{faenc} does not support EVEC-encoding so far.  %todo fix reference
            Thus in case a instruction with explicit rounding mode is encountered, the rounding mode is temporally changed in the \texttt{MXCSR} register.
    \item \textbf{Exception handling} in RISC-V is realized by reading the \texttt{fcsr} floating-point control and status register, traps are not supported.
            The CSR instructions used to read this register are thus emulated to instead read and translate the \texttt{MXCSR} exception flags.
            x86-64 exceptions are meanwhile disabled by masking them in the \texttt{MXCSR} register.
\end{itemize}


\subsection{Optimisations}
\label{sec:optimise}

\subsubsection{Recursive jump translation}
\label{sec:recursive_translation}
Returning from translated guest code to the translator's main transcode loop brings with it the performance penalties imposed by the context switch, code cache lookup, and second context switch necessary for starting execution of the next basic block.
To avoid these negative performance impacts, we employ the method of recursive translation: When the parser arrives at an unconditional jump, translation of the jump target is started recursively.
That way, the jump target will always be translated before the jump itself.
Because the jump target's host code address is now already known at translate time, we can emit a direct jump to the target block instead of returning to the transcode loop.
The blocks containing jump and target are thereby chained.

\subsubsection{Retroactive block chaining}
\label{sec:chaining}
Targets of conditional jumps are not translated recursively, because translation is done lazy, and it is near impossible to know at parse time whether a branch will be taken, and its target should thus be translated, or not.
If the translator reaches a branch, its two sides can only be chained if the target block has already been translated and its host code address is known.
If that is not the case, the target can instead be chained retroactively after the respective side of the branch is first taken: Following translation of the target block, the branches host code is modified to jump to the targets now known address directly, instead of returning to the transcode loop.
Further cache lookups and context switching are thus avoided for this branch.

\subsubsection{Return address stack}
\label{sec:return-address-stack}
Dynamic jumps can not be statically chained, because their target address may vary.
Still, there is potential for optimization, as the majority of dynamic jumps found in a typical program are function returns.
By keeping track of function calls, it is possible to predict the return target addresses.
We use a return address stack which holds pairs consisting of the guest and host code's addresses, implemented as a ring buffer to prevent over- and underflow.
Calls are first detected at parse time and have their return targets recursively translated.
The call's emitted host code will push its return address pair onto the stack at every execution, without having to leave guest context.
Dynamic jumps will then compare their target address with the first element's on the stack, and if it matches, pop the address pair and jump to the target block directly.
In case of a mismatch the stack will not be changed and control is handed back to the translator.


\subsubsection{Macro operation fusion by pattern matching}
\label{sec:pattern-matching}
As RISC-V is a risc- and x86-64 a CISC architecture, RISC-V programs often need more instructions than on x86-64 to achieve the same effect.
We employ a technique known as macro operation fusion to translate specific patterns of RISC-V instructions into shorter, equivalent x86-64 code, thereby increasing the generated code's performance.
The pattern matcher will detect these patterns after parsing, and replace them with special pseudo-instructions, whose translator functions then emit the corresponding sequence of x86-64 instructions at translate time.
Care must be taken when defining the patterns, as code following the pattern might rely on register values written by instructions earlier in the pattern.
Thus, either the emitted x86-64 code has to set these registers as well, or the pattern has only to be applicable if no such writes into later used registers occur.
An exemplary excerpt from the patterns we implemented is shown by table \ref{tab:patterns-table}.

\begin{table*}[t]
	\centering
	\ttfamily
	\small
	\begin{tabular}{ll}
		\toprule
		LUI r1, imm; LW r2, imm(r1); ADDI r2, r2, imm; SW r2, imm(r1); & ADD m32, imm32\\
		LUI r1, imm; LD r2, imm(r1); ADDI r2, r2, imm; SD r2, imm(r1); & ADD m64, imm32\\
		AUIPC r1, imm; ADDI r1, r1; & MOV r64, imm64\\
		AUIPC r1, imm; LW r1, imm(r1); & MOVSX r64, m32\\
		AUIPC r1, imm; LD r1, imm(r1); & MOV r64, imm64\\
		SLLI r1, r1, 32; SLRI r1, r1, 32; & MOV r32, r32\\
		ADDIW r1, r1, imm; SLLI r1, r1, 31; SRLI r1, r1 32 & ADD r32, imm32\\
		\bottomrule
	\end{tabular}
	\caption[Patterns used for macro-op-fusion]%
	{Some examples of patterns currently fused by the translator, the last five taken from rv8~\cite{clark2017rv8}.}
	\label{tab:patterns-table}
\end{table*}















