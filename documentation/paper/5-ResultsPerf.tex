\begin{table}
	\centering
	\begin{tabular}{rl}
		\toprule
		\textbf{SPECspeed Benchmark} & \textbf{Workload}\\
		\midrule
		\texttt{600.perlbench\_s} & Perl interpreter\\
		\texttt{602.gcc\_s} & GNU C compiler\\
		\texttt{605.mcf\_s} & Route planning\\
		\texttt{620.omnetpp\_s} & Discrete Event simulation -- computer network\\
		\texttt{623.xalancbmk\_s} & XML to HTML conversion via XSLT\\
		\texttt{625.x264\_s} & Video compression\\
		\texttt{631.deepsjeng\_s} & Artificial Intelligence: alpha-beta tree search (Chess)\\
		\texttt{641.leela\_s} & Artificial Intelligence: Monte Carlo tree search (Go)\\
		\texttt{648.exchange2\_s} & Artificial Intelligence: recursive solution generator (Sudoku)\\
		\texttt{657.xz\_s} & General data compression\\
		\bottomrule
	\end{tabular}
	\caption[SPEC CPU 2017 workload description]%
	{A description of the workloads covered by \textit{SPEC CPU 2017}'s \texttt{intspeed} suite~\cite{spec-cpu-doc}.}
	\label{tab:spec-description}
\end{table}


Measuring the performance of the DBT was accomplished by using the tools in \textit{SPEC CPU 2017}'s \texttt{intspeed} suite of benchmarks.
This not only generates reproducible and widely accepted results in the industry, it also validates the results produced during the run, thus ruling out any errors in the benchmark's translation.

The \texttt{intspeed} suite also presents a variety of different workloads to the translator that are based on real-life scenarios, thus producing an accurate and understandable overview of the DBT's performance in a non-controlled environment.
An overview of the workloads covered by the aforementioned suite can be found in table~\ref{tab:spec-description}.
Further context is provided by performance testing using the data compression utility \textit{gzip}~\cite{gzip}, where compression time is compared between runs on a native machine, in QEMU and in the DBT\@.

All testing was performed on an x86--64 8-core \textit{Intel Xeon Bronze 3106} system clocked at $1,70$ GHz base with $78$ GiB of physical memory, running \textit{Ubuntu 18.04.3 LTS}, kernel version \textit{4.15.0-70-generic}.
The DBT was compiled via \texttt{CMAKE\_BUILD\_TYPE} set to \texttt{Release} and \texttt{CMAKE\_INTERPROCEDURAL\_OPTIMIZATION} enabled, which implies \texttt{-O3} and \texttt{-flto -fno-fat-lto-objects}.

\subsection{SPEC CPU 2017 Results}

% ======= SPEC CPU Results =======
% Results of the intspeed SPEC CPU 2017 runs.
% ================================
\pgfplotstableread[col sep=comma]{benchmarks/spec-base/native.csv}\nativetable
\pgfplotstableread[col sep=comma]{benchmarks/spec-base/dbt.csv}\dbttable
\pgfplotstablecreatecol[create col/copy column from table=\nativetable{Est. Base Run Time}]{native}\dbttable
\pgfplotstablecreatecol[create col/expr={\thisrow{Est. Base Run Time} / \thisrow{native}}]{ratio}\dbttable

\pgfplotstablesort[sort key = ratio, sort cmp=float >]\sorteddbttable{\dbttable}

\begin{figure}[h]
	\centering
	\begin{tikzpicture}
		\begin{axis}[%
			title = {SPEC CPU 2017 \texttt{intspeed} Results},
			ybar,
			area legend,
			ylabel = {Execution time [ratio to native]},
			xtick = data,
			xtick style = {draw = none},
			xticklabel style = {
				inner sep = 0pt,
				anchor = north east,
				rotate = 60
			},
			ytick = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0},
			scaled y ticks = false,
			xticklabels from table={\sorteddbttable}{Benchmark},
			ymin = 0, ymax = 6.5,
			ymajorgrids = true,
			bar width = 5pt,
			height = 7.0cm,
			width = 0.9\linewidth,
			legend style = {
				at = {(0.98, 0.97)},
				anchor = north east,
				legend columns = 3,
				column sep = 0.2cm
			}
		]
			% Native results
			\pgfplotstableread[col sep=comma]{benchmarks/spec-base/native.csv}\nativelocaltable
			\pgfplotstablecreatecol[create col/copy column from table=\nativetable{Est. Base Run Time}]{native}\nativelocaltable
			\pgfplotstablecreatecol[create col/expr={\thisrow{Est. Base Run Time} / \thisrow{native}}]{ratio}\nativelocaltable
			\pgfplotstablesort[sort key = ratio, sort key from ={\dbttable}, sort cmp=float >]\nativelocalsortedtable{\nativelocaltable}
			\addplot+[fill=era-native, draw=black] table [x expr=\coordindex, y=ratio] \nativelocalsortedtable;

			% QEMU results
			\pgfplotstableread[col sep=comma]{benchmarks/spec-base/qemu.csv}\qemutable
			\pgfplotstablecreatecol[create col/copy column from table=\nativetable{Est. Base Run Time}]{native}\qemutable
			\pgfplotstablecreatecol[create col/expr={\thisrow{Est. Base Run Time} / \thisrow{native}}]{ratio}\qemutable
			\pgfplotstablesort[sort key = ratio, sort key from ={\dbttable}, sort cmp=float >]\qemusortedtable{\qemutable}
			\addplot+[fill=era-qemu, draw=black] table [x expr=\coordindex, y=ratio] \qemusortedtable;

			% DBT results
			\addplot+[fill=era-dbt-1, draw=black] table [x expr=\coordindex, y=ratio] \sorteddbttable;

			\legend{native, QEMU, DBT}
		\end{axis}
	\end{tikzpicture}
	\caption[SPEC CPU 2017 Results]%
	{Results of \texttt{ref}-workload runs of \textit{SPEC CPU 2017}'s \texttt{intspeed} (normalised, lower is better).}
	\label{fig:spec-results}
\end{figure}
% ================================

\subsubsection{Analysis}
Figure~\ref{fig:spec-results} shows normalized performance results of the \textit{SPEC CPU 2017} \texttt{intspeed} benchmarks, effectively showing how much overhead QEMU and our translator caused versus the same benchmark compiled and run natively.
Some of the overhead must of course be attributed to the architectural differences between x86 and RISC-V resulting in needing more instructions in RISC-V assembly than x86.
This means these results do not directly measure the overhead vs.\ native that the whole translator infrastructure (parsing, translation, code cache etc.) causes.
What we can compare though, is the relative results of QEMU and our translator, since both use the same compiler and thus get the same binary.
This means the results are a measure for the relative efficiency of the infrastructure and the quality of the generated code.

Through the various performance optimisations mentioned in section~\vref{sec:optimise} we are able to reach our goal of consistently outperforming QEMU\@.
In some cases the advantage is only slight, but in other workloads like the GCC compiler benchmark the advantage grows to a comfortable $80\,\%$.

Most benchmarks show runtimes of about $1.9$x native with \texttt{x264} and \texttt{perlbench} being the outliers.

\texttt{x264} on x86 heavily takes advantage of vectorisation, which RISC-V does not yet support, meaning that the compiler will have to generate loops that run more often, thus needing significantly more instructions for the same result.
Retrospective vectorisation on the translator side is not easy since this would involve detecting the vectorisable loop patterns on assembler level, a task that even the compiler often isn't very effective at, even though it has the knowledge of the entire program.
There are also instances where it relies heavily on 32 bit integer arithmetic which in RISC-V always causes the results to be sign extended to the 64 bit register width, in comparison to x86 which zero extends in these cases.
Thus many consecutive 32 bit instructions on the same values cause a lot of redundant sign extensions.
A future version of the translator could do the sign extensions lazily to save on a bunch of redundant work in some cases.

The \texttt{perlbench} on the other hand has a lot of conditional branches and jumps in the hot blocks.
This causes a lot of context switches since recursive translation currently is only employed for unconditional branches/calls.
Recursively translating the path that is considered hot by the compiler could improve performance by a bit.
It also potentially causes redundant work for the translator, since jumps to the middle of a basic block currently are handled by treating it like a new block beginning at the jump target.



\subsection{Evaluation of translator optimisations}
\begin{table}
	\centering
	\begin{tabular}{rl}
		\toprule
		\textbf{Option} & \textbf{Description}\\
		\midrule
		\texttt{no-ras} & Disable the return address stack\\
		\texttt{no-chain} & Disable block chaining\\
		\texttt{no-jump} & Disable recursive jump target translation\\
		\texttt{no-fusion} & Disable macro operation fusion\\
		\texttt{none} & All of the above\\
		\bottomrule
	\end{tabular}
	% state: 5afb8706e482917866a3507a54d1512befe56a21
	\caption[Translator optimisation options]%
	{The options for translator optimisations, as seen in \texttt{----optimize=help}.}
	\label{tab:opt-options}
\end{table}

In order to evaluate the optimisations built into the translator, we ran the \textit{SPEC CPU 2017} suite with various combinations of the available optimisation options in the same translator version (\texttt{v1.3.1}, the final release in the project's main development cycle).

The results of these runs can be seen in figure~\ref{fig:opt-compare}, and an overview of the switches specified in the figure's legend can be found in table~\ref{tab:opt-options}.

% ======= Optimisation comparison results =======
% Results of the optimisation option comparisons.
% Show all SPEC run results and analyse below.
% ===============================================
\pgfplotstableread[col sep=comma]{benchmarks/spec-compare/base.csv}\basetable
\pgfplotstableread[col sep=comma]{benchmarks/spec-compare/no-ras.csv}\norastable
\pgfplotstableread[col sep=comma]{benchmarks/spec-compare/no-fusion.csv}\nofusiontable
\pgfplotstableread[col sep=comma]{benchmarks/spec-compare/no-jump-no-ras.csv}\nojumpnorastable
\pgfplotstableread[col sep=comma]{benchmarks/spec-compare/none.csv}\nonetable

\pgfplotstablecreatecol[create col/copy column from table=\basetable{Est. Base Run Time}]{base}\basetable
\pgfplotstablecreatecol[create col/expr={\thisrow{Est. Base Run Time} / \thisrow{base}}]{ratio}\basetable

\pgfplotstablecreatecol[create col/copy column from table=\basetable{Est. Base Run Time}]{base}\norastable
\pgfplotstablecreatecol[create col/expr={\thisrow{Est. Base Run Time} / \thisrow{base}}]{ratio}\norastable

\pgfplotstablecreatecol[create col/copy column from table=\basetable{Est. Base Run Time}]{base}\nofusiontable
\pgfplotstablecreatecol[create col/expr={\thisrow{Est. Base Run Time} / \thisrow{base}}]{ratio}\nofusiontable

\pgfplotstablecreatecol[create col/copy column from table=\basetable{Est. Base Run Time}]{base}\nojumpnorastable
\pgfplotstablecreatecol[create col/expr={\thisrow{Est. Base Run Time} / \thisrow{base}}]{ratio}\nojumpnorastable

\pgfplotstablecreatecol[create col/copy column from table=\basetable{Est. Base Run Time}]{base}\nonetable
\pgfplotstablecreatecol[create col/expr={\thisrow{Est. Base Run Time} / \thisrow{base}}]{ratio}\nonetable

\begin{figure}[h]
	\centering
	\begin{tikzpicture}
		\begin{axis}[%
			title = {Optimisation option evaluation},
			ybar,
			area legend,
			ylabel = {Execution time [ratio to base]},
			xtick = data,
			xtick style = {draw = none},
			xticklabel style = {
				inner sep = 0pt,
				anchor = north east,
				rotate = 60
			},
			scaled y ticks = false,
			xticklabels from table={\basetable}{Benchmark},
			ytick = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
			ymin = 0, ymax = 10.5,
			ymajorgrids = true,
			bar width = 3pt,
			height = 8.5cm,
			width = 0.9\linewidth,
			legend style = {
				at = {(0.98, 0.97)},
				anchor = north east,
				legend columns = 3,
				column sep = 0.2cm
			}
		]
			% base results
			\addplot+[fill=era-native, draw=black] table [x expr=\coordindex, y=ratio] \basetable;
			
			% no-fusion results
			\addplot+[fill=era-dbt-1, draw=black] table [x expr=\coordindex, y=ratio] \nofusiontable;

			% no-ras results
			\addplot+[fill=era-qemu, draw=black] table [x expr=\coordindex, y=ratio] \norastable;
			
			% no-jump-no-ras results
			\addplot+[fill=era-dbt-2, draw=black] table [x expr=\coordindex, y=ratio] \nojumpnorastable;
			
			% none results
			\addplot+[fill=era-dbt-3, draw=black] table [x expr=\coordindex, y=ratio] \nonetable;

			\legend{base, \texttt{no-fusion}, \texttt{no-ras}, \texttt{no-jump}{,~} \texttt{no-ras}, \texttt{none}}
		\end{axis}
	\end{tikzpicture}
	\caption[Translator optimisation evaluation results]%
	{Results of \texttt{ref}-workload runs of \textit{SPEC CPU 2017}'s \texttt{intspeed} with various optimisation option combinations (normalised, lower is better).}
	\label{fig:opt-compare}
\end{figure}
% ================================


Macro operation fusion does not seem to provide a lot of a performance benefit, in most benchmarks the numbers do not even suggest any performance increase above natural deviation of benchmark runs.
This means the implemented pattern matching did not give the desired effect of a good performance increase.
Further tweaking of the checked patterns might make this optimisation more worth it.

The return address stack gave a significant advantage in some benchmarks.
Especially the function call heavy 620, 623, 631, 641 benchmarks showed good performance gains of over $50\,\%$.
The 600, 648, 657 benchmarks where most of the runtime is spent in only a couple loops naturally could not benefit a lot.

Recursive jump translation without also utilizing the return address stack only provided a performance increase over disabling both in some benchmarks.
The main reason for this might be that this also makes context switches necessary on unconditional jumps that aren't function calls or returns.
This makes jump heavy benchmarks take a performance hit while jump light benchmarks are almost unaffected.

Expectedly the highest performance penalty was incurred by disabling chaining as well.
This makes a context switch back to the translator necessary for every executed basic block.
The benchmarks that had lower performance losses are the ones were less basic blocks were executed relative to their runtime.
This can be justified by seeing that the most executed parts of the these benchmarks are blocks that are very long.

Something that also needs to be noted that the lazy replacement register handling described in section~\vref{sec:reg-handle} had a high impact in some benchmarks, most notably 657, providing a roughly $45\,\%$ performance increase there more than any other optimisation apart from chaining.

\subsection{Data compression via gzip}
% gzip results
Next to the results of the \textit{SPEC CPU 2017} suite, it is also valuable to measure the performance of the translator in real-world workloads by running data compression via \textit{gzip}.

For better comparability, both the native and RISC-V \textit{gzip} binaries were compiled manually with the compiler optimisation level \texttt{-O3} alongside the linker flag \texttt{-static}.
The RISC-V ABI was setup with \texttt{-march=rv64ima} and \texttt{-mabi=lp64}.

% ======= gzip execution time =======
% Execution time of compression (500 MB, 5 runs).
% ===================================
\begin{figure}[h]
	\centering
	\begin{tikzpicture}
		\begin{axis}[%
			title = {Random Data Compression (\textit{gzip}, 500 MB, 5 runs)},
			xbar,
			area legend,
			xlabel = {Execution time [ratio to native] (lower is better)},
			symbolic y coords = {Native,QEMU,DBT,\ldots unoptimised},
			xmin = 0,
			bar shift = 0.0cm,
			y dir = reverse,
			enlarge y limits = {value=0.2, auto},
			xmajorgrids = true,
			height = 5.5cm,
			width = 13.0cm,
			legend style = {
				at = {(0.5, -0.45)},
				anchor = north,
				legend columns = 4,
				column sep = 0.2cm
			}
		]
			\addplot+ [
				fill=era-native,
				draw=black
			] coordinates {
				(1.0,Native) % 44.15
			};

			\addplot+ [
				fill=era-qemu,
				draw=black
			] coordinates {
				(2.767157418,QEMU) % 122.17
			};
			
			\addplot+ [
				fill=era-dbt-1,
				draw=black
			] coordinates {
				(1.911438279,DBT) % 84.39
			};
			
			\addplot+ [
				fill=era-dbt-2,
				draw=black
			] coordinates {
				(9.527180068,\ldots unoptimised) % 420.625
			};
			
			\legend{Native, QEMU, DBT, DBT unoptimised}
		\end{axis}
	\end{tikzpicture}
	\caption[Execution time of gzip compression]%
	{Execution time of gzip file compression (500 MB of random data, 5 runs) in seconds (normalised, lower is better).\\Unoptimised run executed with \texttt{----optimize=none}.}
	\label{fig:gzip-execution-time}
\end{figure}
% ===================================

Figure~\vref{fig:gzip-execution-time} lists the execution times of \textit{gzip} compressing a pseudo-random $500$ MB file sourced from \texttt{/dev/urandom}\footnote{Reproducible via \texttt{base64 /dev/urandom | head -c 524288000 > random.txt;}}.

Through our very efficient return address stack, recursive jump target translation, macro operation fusion and, most importantly, block chaining we are able to significantly outperform QEMU in random data compression by nearly 45\,\%.
The achieved performance of approximately two times the execution time of a native run is in line with the \textit{SPEC CPU 2017} results shown in figure~\ref{fig:spec-results}.

As mentioned in the caption, the unoptimised run was performed with the command line option \texttt{----optimize=none}, which disables all of the optimisation features mentioned above.
The translator will then have to translate every block one-by-one, jump back into the main loop on every block end and fetch the next position based on the current program counter.






















